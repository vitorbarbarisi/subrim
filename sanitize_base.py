#!/usr/bin/env python3
"""
Sanitize Base - Limpa arquivos base.txt removendo erros e caracteres especiais

Usage: python3 sanitize_base.py <directory_name>
Example: python3 sanitize_base.py onibus133

O script:
1. Verifica se a word-api est√° funcionando (se n√£o estiver, encerra com erro)
2. Encontra o arquivo base.txt ou *_zht_secs_base.txt no diret√≥rio assets/<directory_name>
3. Remove linhas espec√≠ficas que contenham erro de tradu√ß√£o
4. Remove caracteres especiais da coluna chinesa (zht)
5. Integra com word-api para filtrar palavras por confidence_level
6. Salva o arquivo modificado no mesmo local

Linhas removidas:
- "Infelizmente, n√£o h√° uma frase em chin√™s fornecida para eu extrair e traduzir..."
- "A frase fornecida √© muito curta e n√£o cont√©m palavras chinesas para extrair..."
- "A frase fornecida est√° vazia, portanto, n√£o h√° palavras para extrair e traduzir."
- Linhas onde a coluna chinesa cont√©m apenas "‚ô™" (sem conte√∫do chin√™s)

Caracteres removidos da coluna chinesa:
- ‚ô™ (notas musicais)
- ‚Ä¶ (retic√™ncias chinesas)
- „Äê„Äë (colchetes chineses)
- [] (colchetes simples)
- Caracteres alfanum√©ricos (A-Z, a-z, 0-9)
- Outros caracteres especiais problem√°ticos

Integra√ß√£o com word-api:
- Para cada palavra em mandarim nos pares de tradu√ß√£o:
  - Faz GET para http://localhost:7998/word-api/{palavra}
  - Se confidence_level == 3: remove a palavra do array
  - Se n√£o existir: faz POST para adicionar com confidence_level = 1
- Palavras com confidence_level != 3 s√£o mantidas no arquivo
"""

import sys
import argparse
import os
import requests
import json
import re
from pathlib import Path

# Frases espec√≠ficas que indicam erro de tradu√ß√£o e devem ser removidas
ERROR_TRANSLATION_TEXTS = [
    "Infelizmente, n√£o h√° uma frase em chin√™s fornecida para eu extrair e traduzir. Por favor, envie a frase em chin√™s tradicional para que eu possa ajud√°-lo.",
    "A frase fornecida √© muito curta e n√£o cont√©m palavras chinesas para extrair. Por favor, forne√ßa uma frase em chin√™s tradicional para que eu possa realizar a extra√ß√£o conforme solicitado.",
    "A frase fornecida est√° vazia, portanto, n√£o h√° palavras para extrair e traduzir."
]

# URL da word-api localhost
WORD_API_BASE_URL = "http://localhost:7998/word-api"


def check_word_api_health() -> bool:
    """
    Verifica se a word-api est√° funcionando.
    
    Returns:
        True se a API est√° funcionando, False caso contr√°rio
    """
    try:
        print("üîç Verificando status da word-api...", flush=True)
        response = requests.get(f"{WORD_API_BASE_URL}/health", timeout=5)
        
        if response.status_code == 200:
            print("‚úÖ Word-api est√° funcionando", flush=True)
            return True
        else:
            print(f"‚ùå Word-api retornou status {response.status_code}", flush=True)
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erro ao conectar com word-api: {e}", flush=True)
        return False
    except Exception as e:
        print(f"‚ùå Erro inesperado ao verificar word-api: {e}", flush=True)
        return False


def get_word_from_api(word: str) -> dict:
    """
    Faz GET para a word-api para verificar se a palavra existe.
    
    Args:
        word: Palavra em mandarim para verificar
        
    Returns:
        dict: Resposta da API ou None se erro
    """
    try:
        url = f"{WORD_API_BASE_URL}/{word}"
        response = requests.get(url, timeout=5)
        
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 404:
            return None  # Palavra n√£o encontrada
        else:
            print(f"‚ö†Ô∏è  Word-api retornou status {response.status_code} para '{word}'")
            return None
            
    except requests.exceptions.RequestException as e:
        print(f"‚ö†Ô∏è  Erro ao consultar word-api para '{word}': {e}")
        return None


def post_word_to_api(word: str, pinyin: str, translation: str, confidence_level: int = 1) -> bool:
    """
    Faz POST para a word-api para adicionar uma nova palavra.
    
    Args:
        word: Palavra em mandarim
        pinyin: Pinyin da palavra
        translation: Tradu√ß√£o da palavra
        confidence_level: N√≠vel de confian√ßa (padr√£o: 1)
        
    Returns:
        bool: True se sucesso, False caso contr√°rio
    """
    try:
        url = f"{WORD_API_BASE_URL}/"
        data = {
            "word": word,
            "pinyin": pinyin,
            "translation": translation,
            "confidence_level": confidence_level
        }
        
        response = requests.post(url, json=data, timeout=5)
        
        if response.status_code in [200, 201]:
            print(f"   ‚úÖ Palavra '{word}' adicionada √† word-api")
            return True
        else:
            print(f"   ‚ö†Ô∏è  Erro ao adicionar '{word}' √† word-api: status {response.status_code}")
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"   ‚ö†Ô∏è  Erro ao adicionar '{word}' √† word-api: {e}")
        return False


def extract_pairs_from_translation(translation_text: str) -> list:
    """
    Extrai pares de palavras da coluna de tradu√ß√£o.
    
    Args:
        translation_text: Texto da coluna de tradu√ß√£o
        
    Returns:
        list: Lista de dicion√°rios com word, pinyin, translation
    """
    pairs = []
    
    if not translation_text or translation_text.strip() == "":
        return pairs
    
    try:
        # Parse do JSON-like array
        import ast
        translation_list = ast.literal_eval(translation_text)
        
        if isinstance(translation_list, list):
            for item in translation_list:
                if isinstance(item, str) and ":" in item:
                    # Formato: "palavra (pinyin): tradu√ß√£o"
                    parts = item.split(":", 1)
                    if len(parts) == 2:
                        word_part = parts[0].strip()
                        translation = parts[1].strip()
                        
                        # Extrai palavra e pinyin
                        pinyin_match = re.search(r'\(([^)]+)\)', word_part)
                        if pinyin_match:
                            pinyin = pinyin_match.group(1)
                            word = word_part.replace(f"({pinyin})", "").strip()
                        else:
                            word = word_part
                            pinyin = ""
                        
                        pairs.append({
                            "word": word,
                            "pinyin": pinyin,
                            "translation": translation
                        })
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erro ao extrair pares de '{translation_text}': {e}")
    
    return pairs


def process_word_api_integration(pairs: list) -> list:
    """
    Processa integra√ß√£o com word-api para cada palavra nos pares.
    
    Args:
        pairs: Lista de pares de palavras
        
    Returns:
        list: Lista de pares filtrada (palavras com confidence_level == 3 removidas)
    """
    filtered_pairs = []
    
    for pair in pairs:
        word = pair["word"]
        pinyin = pair["pinyin"]
        translation = pair["translation"]
        
        # Pula palavras vazias ou inv√°lidas
        if not word or word.strip() == "":
            continue
        
        print(f"   üîç Verificando palavra: '{word}'")
        
        # Consulta a word-api
        api_response = get_word_from_api(word)
        
        if api_response is None:
            # Palavra n√£o encontrada, adiciona √† word-api
            print(f"   üìù Palavra '{word}' n√£o encontrada, adicionando...")
            post_word_to_api(word, pinyin, translation, confidence_level=1)
            filtered_pairs.append(pair)
        else:
            # Palavra encontrada, verifica confidence_level
            confidence_level = api_response.get("confidence_level", 0)
            
            if confidence_level == 3:
                print(f"   üóëÔ∏è  Palavra '{word}' removida (confidence_level == 3)")
                # N√£o adiciona √† lista filtrada
            else:
                print(f"   ‚úÖ Palavra '{word}' mantida (confidence_level == {confidence_level})")
                filtered_pairs.append(pair)
    
    return filtered_pairs


def sanitize_chinese_text(text: str) -> str:
    """
    Remove caracteres especiais do texto chin√™s.

    Args:
        text: Texto chin√™s a ser limpo

    Returns:
        Texto chin√™s sem caracteres especiais
    """
    if not text:
        return text

    # Caracteres a serem removidos
    chars_to_remove = ['„Äê', '„Äë', '[', ']', '{', '\1c&HFF8000&', '}',
        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',
        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
        '√Å', '√â', '√ç', '√ì', '√ö', '√É', '√ï', '√á', '√Ä', '√à', '√å', '√í', '√ô', '√Ç', '√ä', '√é', '√î', '√õ', '√É', '√ï', '√á', '√Ä', '√à', '√å', '√í', '√ô', '√Ç', '√ä', '√é', '√î', '√õ',
        '√°', '√©', '√≠', '√≥', '√∫', '√£', '√µ', '√ß', '√†', '√®', '√¨', '√≤', '√π', '√¢', '√™', '√Æ', '√¥', '√ª', '√£', '√µ', '√ß', '√†', '√®', '√¨', '√≤', '√π', '√¢', '√™', '√Æ', '√¥', '√ª',
        '√¢', '√™', '√Æ', '√¥', '√ª', '√£', '√µ', '√ß', '√†', '√®', '√¨', '√≤', '√π', '√¢', '√™', '√Æ', '√¥', '√ª', '√£', '√µ', '√ß', '√†', '√®', '√¨', '√≤', '√π', '√¢', '√™', '√Æ', '√¥', '√ª',
        '√¢', '√™', '√Æ', '√¥', '√ª', '√£', '√µ', '√ß', '√†', '√®', '√¨', '√≤', '√π', '√¢', '√™', '√Æ', '√¥', '√ª', '√£', '√µ', '√ß', '√†', '√®', '√¨', '√≤', '√π', '√¢', '√™', '√Æ', '√¥', '√ª',
    ]

    # Remove os caracteres especiais
    for char in chars_to_remove:
        text = text.replace(char, '')

    return text.strip()


def process_base_file(base_file_path: Path) -> bool:
    """
    Processa o arquivo base.txt removendo caracteres especiais da coluna chinesa.

    Args:
        base_file_path: Caminho para o arquivo base.txt

    Returns:
        True se processamento bem-sucedido
    """
    print(f"üîç Lendo arquivo: {base_file_path.name}", flush=True)

    try:
        # L√™ todas as linhas do arquivo
        with open(base_file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        print(f"üìä Encontradas {len(lines)} linhas", flush=True)

        # Processa cada linha
        processed_lines = []
        modified_count = 0
        removed_count = 0

        for line_num, line in enumerate(lines, 1):
            line = line.rstrip('\n\r')  # Remove quebras de linha

            if not line.strip():
                processed_lines.append(line)
                continue

            # Divide a linha por tabs
            parts = line.split('\t')

            # Verifica se a coluna chinesa (√≠ndice 2) cont√©m apenas "‚ô™"
            if len(parts) >= 3 and parts[2].strip() == "‚ô™":
                print(f"   üóëÔ∏è  Linha {line_num}: removida (coluna chinesa vazia - apenas ‚ô™)")
                removed_count += 1
                continue
            
            # Verifica se a coluna de tradu√ß√µes (√≠ndice 4) cont√©m alguma das frases de erro de tradu√ß√£o
            if len(parts) >= 5:
                translation_text = parts[4].strip()
                found_error = False
                for error_text in ERROR_TRANSLATION_TEXTS:
                    if translation_text == error_text.strip():
                        print(f"   üóëÔ∏è  Linha {line_num}: removida (erro de tradu√ß√£o)")
                        removed_count += 1
                        found_error = True
                        break
                
                if found_error:
                    continue

            if len(parts) < 4:
                processed_lines.append(line)
                continue

            # A coluna chinesa √© a 4¬™ (√≠ndice 3)
            original_chinese = parts[3]
            sanitized_chinese = sanitize_chinese_text(original_chinese)

            # Verifica se houve modifica√ß√£o
            if sanitized_chinese != original_chinese:
                print(f"   üîß Linha {line_num}: '{original_chinese}' ‚Üí '{sanitized_chinese}'")
                modified_count += 1

            # Processa integra√ß√£o com word-api se houver coluna de tradu√ß√µes
            if len(parts) >= 5:
                translation_text = parts[4].strip()
                if translation_text and translation_text not in ERROR_TRANSLATION_TEXTS:
                    print(f"   üîó Processando word-api para linha {line_num}...")
                    
                    # Extrai pares de palavras da coluna de tradu√ß√µes
                    pairs = extract_pairs_from_translation(translation_text)
                    
                    if pairs:
                        # Processa integra√ß√£o com word-api
                        filtered_pairs = process_word_api_integration(pairs)
                        
                        # Reconstr√≥i a coluna de tradu√ß√µes com pares filtrados
                        if filtered_pairs:
                            new_translation_parts = []
                            for pair in filtered_pairs:
                                if pair["pinyin"]:
                                    new_translation_parts.append(f'"{pair["word"]} ({pair["pinyin"]}): {pair["translation"]}"')
                                else:
                                    new_translation_parts.append(f'"{pair["word"]}: {pair["translation"]}"')
                            
                            new_translation_text = "[" + ", ".join(new_translation_parts) + "]"
                            parts[4] = new_translation_text
                            
                            if new_translation_text != translation_text:
                                print(f"   üîÑ Linha {line_num}: tradu√ß√µes filtradas pela word-api")
                                modified_count += 1
                        else:
                            # Todos os pares foram removidos, marca para remo√ß√£o
                            print(f"   üóëÔ∏è  Linha {line_num}: removida (todos os pares filtrados pela word-api)")
                            removed_count += 1
                            continue

            # Reconstr√≥i a linha com o texto chin√™s limpo
            parts[3] = sanitized_chinese
            processed_lines.append('\t'.join(parts))

        # Salva o arquivo modificado
        print(f"üíæ Salvando arquivo modificado...", flush=True)
        with open(base_file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(processed_lines) + '\n')

        print(f"‚úÖ Processamento conclu√≠do!", flush=True)
        print(f"   üìù {modified_count} linhas modificadas")
        print(f"   üóëÔ∏è  {removed_count} linhas removidas")
        print(f"   üíæ Arquivo salvo: {base_file_path}")

        return True

    except Exception as e:
        print(f"‚ùå Erro ao processar arquivo: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="Remove caracteres especiais da coluna chinesa do arquivo base.txt",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos:
  python3 sanitize_base.py onibus133    # Processa assets/onibus133/base.txt

Funcionamento:
  - Encontra automaticamente o arquivo base.txt no diret√≥rio
  - Remove linhas com erro de tradu√ß√£o espec√≠fico
  - Remove caracteres especiais como ‚ô™, ‚Ä¶, „Äê„Äë, etc.
  - Remove tamb√©m caracteres alfanum√©ricos (A-Z, a-z, 0-9)
  - Salva o arquivo modificado no mesmo local
  - Mostra quais linhas foram modificadas ou removidas
        """
    )

    parser.add_argument('directory', help='Nome do diret√≥rio (sem _sub)')

    args = parser.parse_args()

    # Constr√≥i o caminho para o diret√≥rio
    source_dir = Path('assets') / args.directory

    # Procura pelo arquivo base (pode ser base.txt ou *_zht_secs_base.txt)
    base_file = None

    # Primeiro tenta encontrar base.txt
    if (source_dir / 'base.txt').exists():
        base_file = source_dir / 'base.txt'
    else:
        # Procura por arquivos *_zht*_secs_base.txt (com h√≠fen ou underscore)
        for file_path in source_dir.glob('*zht*_secs_base.txt'):
            base_file = file_path
            break

    print("üßπ Sanitize Base - Limpeza de caracteres especiais", flush=True)
    print("=" * 55)
    print(f"üìÅ Diret√≥rio: {source_dir}")

    # Verifica se o diret√≥rio existe
    if not source_dir.exists():
        print(f"‚ùå Erro: Diret√≥rio {source_dir} n√£o encontrado")
        return 1

    # Verifica se encontrou algum arquivo base
    if not base_file or not base_file.exists():
        print(f"‚ùå Erro: Arquivo base.txt ou *_zht_secs_base.txt n√£o encontrado em {source_dir}")
        return 1

    print(f"üìÑ Arquivo base encontrado: {base_file.name}", flush=True)

    # Verifica se a word-api est√° funcionando antes de processar
    if not check_word_api_health():
        print("\n‚ùå Word-api est√° indispon√≠vel. Encerrando para evitar processamento com API down.")
        return 1

    # Processa o arquivo
    if process_base_file(base_file):
        print("\nüéâ Sanitiza√ß√£o conclu√≠da com sucesso!")
        return 0
    else:
        print("\n‚ùå Erro durante a sanitiza√ß√£o")
        return 1


if __name__ == "__main__":
    sys.exit(main())
